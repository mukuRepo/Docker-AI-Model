{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "414315c1-cfab-45fe-abed-a2db11375d68",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings \n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# basic librareis\n",
    "import zipfile\n",
    "import glob\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "# plotting and visualizations\n",
    "import matplotlib \n",
    "import matplotlib.pyplot as plt \n",
    "%matplotlib inline\n",
    "import seaborn as sns \n",
    "import missingno as msno\n",
    "\n",
    "# preprocessing\n",
    "from keras.preprocessing.image import (ImageDataGenerator, \n",
    "                                       img_to_array, \n",
    "                                       array_to_img, \n",
    "                                       load_img)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# metrics\n",
    "from sklearn.metrics import (confusion_matrix, \n",
    "                             classification_report, \n",
    "                             accuracy_score, \n",
    "                             f1_score, \n",
    "                             roc_auc_score)\n",
    "# modeling\n",
    "import tensorflow as tf\n",
    "from keras.models import Model,Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Dropout, Dense,Flatten\n",
    "\n",
    "from keras.applications import resnet50\n",
    "from keras.applications.resnet50 import preprocess_input\n",
    "from keras import optimizers\n",
    "from keras import regularizers\n",
    "from keras.callbacks import EarlyStopping,LearningRateScheduler\n",
    "\n",
    "\n",
    "from keras import backend as K\n",
    "K.clear_session()\n",
    "\n",
    "# model plotting\n",
    "from IPython.display import SVG\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "from keras.utils import plot_model\n",
    "\n",
    "# mesc\n",
    "from sklearn.utils import shuffle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d91ea160-9bb1-429e-8ef2-27d989c49fb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extraction of train and test data from zipfiles to data folder\n",
    "print('Extracting the data from dataset.....\\n')\n",
    "zip_files = glob.glob('/dogs-vs-cats/*.zip')\n",
    "\n",
    "print('{} files found in the input directory\\n'.format(str(len(zip_files))))\n",
    "\n",
    "for file in zip_files:\n",
    "    with zipfile.ZipFile(file, 'r') as Z:\n",
    "        Z.extractall('data')\n",
    "    print('{} is extracted\\n'.format(file.split('/')[-1]))\n",
    "\n",
    "print('Extraction is completed\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d924b7bf-c429-45e0-b23a-359ebb2dfb43",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = '/data/train/'\n",
    "test_dir = '/data/test1/'\n",
    "print('Total Images in Train, and Test Data...')\n",
    "print('\\nNo. of Train Images: ' + str(len(os.listdir(train_dir))))\n",
    "print('No. of Test Images: ' + str(len(os.listdir(test_dir))) + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "265ab8f3-663c-4536-bf6f-fa3c1f05af12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# category and filepath extraction helper functions\n",
    "def category(path):\n",
    "    return [file.split('.')[0] for file in os.listdir(path)]\n",
    "\n",
    "def filename(path):\n",
    "    return [file for file in os.listdir(path)]\n",
    "\n",
    "# image names and labels\n",
    "x_train_imgname = filename(train_dir)\n",
    "x_test_imgname = filename(test_dir)\n",
    "y_train_label = category(train_dir)\n",
    "\n",
    "# creation of total dataframe and submission dataframe\n",
    "print('Image data is storing into dataframes...\\n')\n",
    "train_image_df = pd.DataFrame({'filename': x_train_imgname, 'category': y_train_label})\n",
    "submission_image_df = pd.DataFrame({'filename': x_test_imgname})\n",
    "\n",
    "print('Training image names and labels are read to train_image_df\\n')\n",
    "print('Testing image names are read to submission_image_df\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27313567-08fa-4ab9-9704-08e1d53656c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper functions\n",
    "def img_path(directory):\n",
    "\n",
    "    paths = []\n",
    "    cate = []\n",
    "    ID_no = []\n",
    "    for file in os.listdir(directory):\n",
    "        path = os.path.join(directory, file)\n",
    "        paths.append(path)\n",
    "        cate.append(file.split('.')[0])\n",
    "        ID_no.append(file.split('.')[1])\n",
    "    return ID_no, paths, cate\n",
    "\n",
    "def showImages(data, num_row=3, num_col=3, name='any', subtitle='off'):\n",
    "\n",
    "    # little data sorting\n",
    "    cat_df, dog_df = data[data['Category'] == 'cat'], data[data['Category'] == 'dog']\n",
    "\n",
    "    if name == 'dog':\n",
    "        X, Y  = dog_df['img_paths'], dog_df['ID_no']\n",
    "    elif name == 'cat':\n",
    "        X, Y  = cat_df['img_paths'], cat_df['ID_no']     \n",
    "    else:\n",
    "        X, Y  = data['img_paths'], data['ID_no']     # could use try and except but let's stick to minimal code\n",
    "\n",
    "    (X_rand, Y_rand) = shuffle(X, Y)\n",
    "    \n",
    "    # showing images on matplotlib \n",
    "    \n",
    "    fig, ax = plt.subplots(num_row, num_col, figsize=(12, 12), dpi=100)\n",
    "    fig.patch.set_facecolor('#f5f6f6')\n",
    "    axes = ax.ravel()\n",
    "    \n",
    "    for idx, ax in enumerate(axes):\n",
    "        x = load_img(X_rand.iloc[idx], target_size=(125, 125))\n",
    "        ax.imshow(x)\n",
    "        if subtitle == 'on':\n",
    "            ax.set_title(\"{}\".format(Y_rand.iloc[idx]))\n",
    "        else:\n",
    "            ax.set_title('')\n",
    "        ax.axis('off')\n",
    "        plt.subplots_adjust(wspace=0)\n",
    "        del x\n",
    "    \n",
    "    fig.text(0.1, 0.93, 'Hey Siri! is it a Cat or Dog?: {}s from Training Data'.format(name.capitalize()), {'fontfamily': 'serif', 'size': 18, 'weight': 'bold'})\n",
    "    \n",
    "    return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5799bb38-9b22-4fba-8193-cabffc679f4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implementing above function over the train dataset\n",
    "ID_no, img_paths, train_images = img_path(train_dir)\n",
    "\n",
    "print('\\nDataframe is creating for training image visualization in a grid...\\n')\n",
    "# creating a new dataframe for data visualization\n",
    "visual_df = pd.DataFrame({'ID_no': ID_no, 'Category': train_images, 'img_paths': img_paths})\n",
    "\n",
    "print('\\n'); print(visual_df.head(5))\n",
    "\n",
    "print('\\nDone!\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "091ddc1a-009e-4691-9c46-bd740e14b6c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data split into train data and validation data\n",
    "train_valid_df, test_df = train_test_split(train_image_df, test_size=0.04)\n",
    "train_df, valid_df = train_test_split(train_valid_df, test_size=0.2)\n",
    "\n",
    "train_images = train_df.shape[0]\n",
    "valid_images = valid_df.shape[0]\n",
    "holdon_images = test_df.shape[0]\n",
    "test_images = submission_image_df.shape[0]\n",
    "\n",
    "print('\\nNumber of Training Images: ' + str(train_images))\n",
    "print('\\nNumber of Validating Images: ' + str(valid_images))\n",
    "print('\\nNumber of Holdon Images: ' + str(holdon_images))\n",
    "print('\\nNumber of Testing Images: ' + str(test_images))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "295b56ef-0611-438e-a293-cb5c511a1b36",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_size = 224\n",
    "batch_size = 128\n",
    "\n",
    "print(color.BOLD_COLOR + '\\nPreparing train and validation images for training...' + color.END)\n",
    "# dataframe iterators without data agumnetation\n",
    "\n",
    "train_map = ImageDataGenerator()\n",
    "valid_map = ImageDataGenerator()\n",
    "test_map =  ImageDataGenerator()\n",
    "\n",
    "print(color.BOLD)\n",
    "        \n",
    "#Creatinga a dataframe iterators for fitting\n",
    "vani_train_data = train_map.flow_from_dataframe(\n",
    "            train_df,train_dir,\n",
    "            x_col = 'filename',\n",
    "            y_col = 'category',\n",
    "            target_size = (img_size, img_size),\n",
    "            batch_size = batch_size,\n",
    "            class_mode = 'categorical')\n",
    "\n",
    "vani_valid_data = valid_map.flow_from_dataframe(\n",
    "             valid_df, train_dir,\n",
    "             x_col = 'filename',\n",
    "             y_col = 'category',\n",
    "             target_size = (img_size, img_size),\n",
    "             batch_size = batch_size,\n",
    "             class_mode = 'categorical')\n",
    "\n",
    "\n",
    "vani_test_data = test_map.flow_from_dataframe(\n",
    "             test_df, train_dir,\n",
    "             x_col = 'filename',\n",
    "             y_col = None,\n",
    "             target_size = (img_size, img_size),\n",
    "             batch_size = batch_size,\n",
    "             class_mode = None,\n",
    "             shuffle = False)\n",
    "\n",
    "print(color.BOLD_COLOR + '\\nDone!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83e3266e-2280-4945-abc1-ddc51edc6cde",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Building model computational graph\n",
    "vani_model = Sequential()\n",
    "vani_model.add(Conv2D(16, (3,3), activation = 'relu', padding = 'same', input_shape = (224,224,3)))\n",
    "vani_model.add(Conv2D(16, (3,3), activation = 'relu', padding = 'same'))\n",
    "vani_model.add(MaxPooling2D(pool_size = (2,2), strides=(2,2)))\n",
    "\n",
    "vani_model.add(Conv2D(32, (3,3), activation = 'relu', padding = 'same'))\n",
    "vani_model.add(Conv2D(32, (3,3), activation = 'relu', padding = 'same'))\n",
    "vani_model.add(MaxPooling2D(pool_size = (2,2), strides=(2,2)))\n",
    "\n",
    "vani_model.add(Conv2D(64, (3,3), activation = 'relu', padding = 'same'))\n",
    "vani_model.add(Conv2D(64, (3,3), activation = 'relu', padding = 'same'))\n",
    "vani_model.add(MaxPooling2D(pool_size = (2,2),strides=(2,2)))\n",
    "\n",
    "vani_model.add(Conv2D(128, (3,3), activation = 'relu', padding = 'same'))\n",
    "vani_model.add(Conv2D(128, (3,3), activation = 'relu', padding = 'same'))\n",
    "vani_model.add(MaxPooling2D(pool_size = (2,2),strides=(2,2)))\n",
    "\n",
    "vani_model.add(Dropout(0.3))\n",
    "\n",
    "vani_model.add(Conv2D(256, (3,3), activation = 'relu', padding = 'same'))\n",
    "vani_model.add(Conv2D(256, (3,3), activation = 'relu', padding = 'same'))\n",
    "vani_model.add(MaxPooling2D(pool_size = (2,2),strides=(2,2)))\n",
    "\n",
    "vani_model.add(Dropout(0.3))\n",
    "\n",
    "vani_model.add(Flatten())\n",
    "\n",
    "vani_model.add(Dense(512, activation = 'relu'))\n",
    "\n",
    "vani_model.add(Dropout(0.5))\n",
    "\n",
    "vani_model.add(Dense(2, activation = 'softmax'))\n",
    "\n",
    "print('\\nVanilla Model layers and output shapes with params...\\n')\n",
    "vani_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21867ee4-5fe1-477f-ad7a-e70995acb145",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compiling model with loss, opt, metrics\n",
    "loss = 'categorical_crossentropy'\n",
    "opt = tf.keras.optimizers.Adam(learning_rate=0.0001, beta_1=0.9, beta_2=0.999, epsilon=1e-07)\n",
    "metrics = ['accuracy']\n",
    "\n",
    "vani_model.compile(loss=loss, optimizer=opt, metrics=metrics)\n",
    "\n",
    "print('Training on Vanilla CNN has started ....\\n')\n",
    "# fitting the model for the training dataset\n",
    "vani_history = vani_model.fit(vani_train_data, epochs=15,\n",
    "                              validation_data=vani_valid_data,\n",
    "                              validation_steps=valid_images // batch_size,\n",
    "                              steps_per_epoch=train_images // batch_size)\n",
    "\n",
    "print('\\nDone!\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0c405a2-1704-49f3-a9a0-2981b313cc2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb733b60-c565-45d5-bb94-adda175e8286",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_save_path = Path(\"/\")  # Change to the desired path\n",
    "model_save_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "model_filename = \"vani_model.h5\"\n",
    "model_filepath = model_save_path / model_filename\n",
    "\n",
    "vani_model.save(model_filepath)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
